# Cline Model Files Repository for Ollama Local hosting

Welcome to the Cline Model Files Repository. This repository is dedicated to collecting and sharing model files compatible with the Cline AI coding assistant.

inspired by remedyreport on discord and [his video](https://www.youtube.com/watch?v=Z0Ec3dtQS2I&t=1s)

Who was also inspired by [this article](https://note.com/cppp_cpchan/n/n92c7795f5939) (japanese)

## Starting assumptions

**You want free local coding via LLMs!  You are tired of "rate limits" and crazy API fees!**
( also you don't mind it running slower )

- You are running [Ollama.com](https://www.ollama.com) locally
- You are running [cline](https://github.com/cline/cline) or [roo code](https://github.com/RooVetGit/Roo-Code) in VS Code as an extension.
- You want to enable all the tools and features of cline/roo code with local models via ollama.

## Contribution Guidelines

We encourage the community to contribute by submitting model files through Pull Requests (PRs). To ensure consistency and quality, please adhere to the following guidelines:

1. **Fork the Repository:**
   - Click on the "Fork" button at the top right corner of this repository to create your own copy.

2. **Clone Your Fork:**
   - Clone your forked repository to your local machine using:
     ```
     git clone https://github.com/sjdthree/cline_modelfiles.git
     ```

3. **Add Your Model File:**
   - Place your model file in an appropriate directory within the repository.  Or create a new one and place it there for new models.

4. **Submit a Pull Request:**
   - Before submitting, ensure you've completed the PR template provided in `.github/PULL_REQUEST_TEMPLATE.md`.
   - Provide detailed information about your model, including:
     - Original model download URL.
     - Hardware specifications used for testing.
     - Performance metrics achieved.
     - Any additional notes or known issues.

## Testing and Performance

When contributing a model, it's crucial to provide performance metrics to help others understand its capabilities and requirements. Please include:

- **Hardware Specifications:** Details about the CPU, RAM, and GPU used.
- **Testing Environment:** Operating system and any software dependencies.
- **Performance Achieved:** Metrics such as tokens per second and total inference time.

## Support and Discussion

For questions, discussions, or support, please open an issue in this repository. We welcome community engagement and are here to assist.

Thank you for your contributions!
